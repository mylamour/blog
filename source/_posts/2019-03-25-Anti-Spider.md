---
layout: post
title: 走出反爬困境
categories: 安全工程师
kerywords: 思考 反思 问题 工作经验 总结 反爬 爬虫 Spider Anti-Spider
tags: 反爬
---

# 前言

爬虫技术早已屡见不鲜，网上也充斥着各种教程。但是针对反爬技术而言，大家似乎都秘而不宣，遮遮掩掩。其实也正是由于这种遮掩的心态，自以为掌握了核心技术，（其实大都是闭门造车）结果效果却不是那么让人满意，而且要在无尽的规则维护和开关状态中度过。

同样，在大厂，这个东西很多时候(一直)都是黑盒不透明的。连wiki都是单独的优先级(当然这是一个好的管控措施)。至于我在这里并不涉及到反爬自研的工作。因此决定将自己过往中反爬的设计思路及经验技巧梳理出来，以飨读者。

# 概览

先前曾在[反垃圾注册](https://github.com/mylamour/blog/issues/34)中简单的介绍过一些加签验签的东西，后来又简单梳理了一下整个请求生命周期中的反爬技巧![mthink](https://img.iami.xyz/images/47093786-7c5b9100-d25c-11e8-88fa-f97c50b980a2.png)。接下来我们从整体来看下怎么去设计反爬系统。(图是几个月之前画的，有些部分还可以增加，暂时没加)

## 理解业务

正所谓知己知彼，百战不殆。明确业务中存在的数据展示场景，并优先治理爬虫热衷的业务场景，才是解决问题的首要之选。

* 明确业务提供的东西
* 明确爬虫想要的东西
* 明确风险项

注意避免因为逻辑设计错误导致的数据泄露，这种情况下将极大的削弱反爬系统的作用，甚至趋近于零。

## 收集数据

有的数据我们用，没有的数据我们造(创造机会去收集)。从前端到网络到后端，整个流程中能够采集到非常多的数据。这个过程应该思考去采集哪些数据，怎么存储，怎么反哺？一个良好的身份认证体系和完善的数据处理流程将能在处置动作中起到关键作用。我会从，**数据产生**，**数据标识**以及**数据属性**三个角度去解释。
请思考：

### 数据产生

* 用户一次完整的交互过程中产生了哪些数据？缺失了哪些数据？(比如说，缺乏击键间隔，那么我们如何采集到这个数据？)
* 收集到的数据存储到什么地方？前端后端网络端产生的数据怎么聚合到一起？又需要怎么样去反哺检测措施？

我们来看一个非常简单的图，![image](https://img.iami.xyz/images/54924594-b2a5e680-4f47-11e9-8827-ba8245245ca2.png)
从这个简图中先去了解下常规的反爬系统是如何设计的。结合到前面说到过的理解业务，当你设计反爬系统的时候，肯定不仅仅希望能够处理通用场景的反爬，可能还希望处理业务级别的，甚至接口级别的。(针对业务和接口进行单独设置,而非通用场景)。可以很明显的看出，处置名单及动作的产生依赖于数据收集和分析计算。同样还需要明白的几点是:

### 数据标识

* 身份认证体系
* 端上防控(无论是加签验签，设备指纹。这些算法都面临着通过逆向，模拟，代理的方式被破解掉，对这些的的防控也是十分有必要的)

身份认证体系是一个大的概念，![image](https://img.iami.xyz/images/54925119-a5d5c280-4f48-11e9-8c46-7efbb9daf1dc.png)在用户的一此请求中，怎么样尽可能的使标识具有唯一性是一个很大的挑战。人的身份认证，设备的认真，账户的认证，网络环境以及等等。

在这个尝试标识的过程中还会产生大量的数据。如果是你，你觉得从哪些维度标识出一个唯一的实体？
![image](https://img.iami.xyz/images/54925811-06b1ca80-4f4a-11e9-8359-e757b543e002.png)

### 数据特征

数据的特征有来自数据本身的特征，也有经过统计分析得到的特征。因为数据本身的特征不一定完全满足需要，往往需要人工进行提取额外的特征。

* 根据实体属性得到的特征(human, ip, location,devices等分别具有哪些特征?)
* 根据统计分析得到的特征(频次,间隔,页面相似度等)

## 分析计算

一个标准的计算引擎应当包含在线和离线计算，一个用于实时计算，一个用于T+1反哺(弥补名单，也许不是T+1)。

* 根据计算实时性分为Online/Offline计算
* 根据计算方法分为规则引擎和模型引擎(一般规则引擎用于字符的匹配检测，模型引擎用于离线分析等)

好了，关于机器学习算法在安全领域的应用我也不想再强调什么了。规则引擎似乎也是套路依旧。Boost类算法一把梭？ XGBoost,light GBM, CatBoost不了解一下吗？祖传的参数还有用吗？

## 处置响应

这一部分才是 Anti-Spider真正执行动作的部分。同时声明，BAN IP 一直都不是个最好的选择。还要明确的是，要确保你的处置动作不要被bypass了(不仅在收集数据的过程中面临Bypass的风险，在整个检测到处置的链路中任何一环都有可能面临bypass的风险，只不过是不是在可接受范围而已。)

* Action:  Ban, Deny, Delay, Waiting, Login, Capture, Poison, Honey Pot.
* Plateform: Andorid, IOS, Browser(Chrome, Firefox, Opera, IE...)


# 检测框架

OK。当我们有能力从技术角度设计一个反爬系统了，落实的时候还需要考虑哪些问题？

* 面向业务: 接入方式，接入场景
* 面向运营: 规则运营，规则维护，模型更新等
* 面向运维: 稳定性，可用性，热更新，模型部署，模型维护，指标相关(成功率，失败率)，降级开关等

考虑了这么多问题，其实才能算的上设计一个完整的反爬系统。在经过完备的考虑后，就应该开始针对整个系统进行技术选型，同时设计好每一个流程中应该处理的东西。前端日志收集存储怎么去做，后端日志收集怎么去做，ETL怎么做，消息推送，规则引擎，计算架构选型等等。


# 总结

真正的反爬不应该是完全的依赖手工的规则增删，否则和传统的WAF检测,webshell检测中输出专家经验没有什么区别。专注点应该在于引进新技术，同时还应该做到自动化(毕竟手动的变更往往会带来更多的不可欺事故。) 认真思考思考，What the hell's going on.

* 面向对象的设计思想用于系统设计也是很好的额
* 有时候需要看些非技术书籍去开阔视野和思路

# 资源

* [反垃圾注册](https://github.com/mylamour/blog/issues/34)
* [反爬脑图](https://img.iami.xyz/images/47093786-7c5b9100-d25c-11e8-88fa-f97c50b980a2.png)
